{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/selfeat_customer_churn.csv')\n",
    "data = data.replace({'Churn?':{'True.':1, 'False.':0}})\n",
    "X = data.drop(['Churn?'], axis=1)\n",
    "y = data['Churn?']\n",
    "del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build prediction models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare classifiers with default setting, offcourse we can tune the parameters for better performance\n",
    "rf = RandomForestClassifier()\n",
    "ab = AdaBoostClassifier()\n",
    "knn = KNeighborsClassifier()\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "estimators = [rf, ab, knn, dt]\n",
    "names = ['Random Forest', 'Ada Boost', 'kNN', 'Decision Tree']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 scores of 5 cross validation: ['0.752', '0.803', '0.848', '0.853', '0.792']\n",
      "Random Forest mean f1: 0.809 with standard deviation: 0.038\n",
      "f1 scores of 5 cross validation: ['0.740', '0.811', '0.839', '0.789', '0.770']\n",
      "Ada Boost mean f1: 0.790 with standard deviation: 0.034\n",
      "f1 scores of 5 cross validation: ['0.545', '0.557', '0.619', '0.617', '0.584']\n",
      "kNN mean f1: 0.585 with standard deviation: 0.030\n",
      "f1 scores of 5 cross validation: ['0.745', '0.755', '0.805', '0.766', '0.779']\n",
      "Decision Tree mean f1: 0.770 with standard deviation: 0.021\n"
     ]
    }
   ],
   "source": [
    "#split data into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "#evaluate the performance of the prediction models\n",
    "for i,e in enumerate(estimators):\n",
    "    scores = cross_val_score(estimator=e, X=X_train, y=y_train, cv=5, scoring='f1')\n",
    "    print('f1 scores of 5 cross validation:',['%0.3f' %(s) for s in scores])\n",
    "    print(names[i] + \" mean f1: %0.3f with standard deviation: %0.3f\" %( scores.mean(),  scores.std()))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From several prediction models, Random Forest achieves the best performance. Therefore, the random Forest prediction model will be used to predict data test, whether a customer will churn or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict customer in data test  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rf.fit(X_train, y_train)\n",
    "predict_val = model.predict(X_test)\n",
    "predict_prob = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    ========================================================================\n",
      "                    Real condition      Predicted as        prob. stay          prob. churn         \n",
      "                    ========================================================================\n",
      "                    ['churn']           ['churn']           0.2                 0.8                 \n",
      "                    ['churn']           ['stay']            0.7                 0.3                 \n",
      "                    ['churn']           ['churn']           0.0                 1.0                 \n",
      "                    ['stay']            ['churn']           0.4                 0.6                 \n",
      "                    ['churn']           ['churn']           0.0                 1.0                 \n",
      "                    ['stay']            ['stay']            0.8                 0.2                 \n",
      "                    ['stay']            ['stay']            0.9                 0.1                 \n",
      "                    ['stay']            ['stay']            0.9                 0.1                 \n",
      "                    ['stay']            ['stay']            0.6                 0.4                 \n",
      "                    ['churn']           ['churn']           0.4                 0.6                 \n",
      "                    ========================================================================\n"
     ]
    }
   ],
   "source": [
    "#print the first 10 prediction result\n",
    "y_test = np.asarray(pd.DataFrame(y_test).replace({0:'stay', 1:'churn'}))\n",
    "predict_val = np.asarray(pd.DataFrame(predict_val).replace({0:'stay', 1:'churn'}))\n",
    "\n",
    "row_val = [[str(y_test[i]),str(predict_val[i]),str(predict_prob[i][0]), str(predict_prob[i][1])] for i in range(10)]\n",
    "\n",
    "header = [\"Real condition\", \"Predicted as\", \"prob. stay\", \"prob. churn\"]\n",
    "row_format =\"{:<20}\" * (len(header)+1)\n",
    "\n",
    "print(\"                    ========================================================================\")\n",
    "print(row_format.format(\"\", *header))\n",
    "print(\"                    ========================================================================\")\n",
    "for row in row_val:\n",
    "    print(row_format.format(\"\",*row))\n",
    "print(\"                    ========================================================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are four condition regarding the prediction result:\n",
    "1. TP : a customer is predicted as churn and in the reality he/she is churn\n",
    "2. TN : a customer is predicted as stay and in the reality he/she is stay\n",
    "3. FP : a customer is predicted as churn but in the reality he/she is stay\n",
    "4. FN : a customer is predicted as stay but in the reality he/she is churn\n",
    "\n",
    "If it is assumed that a customer who want to churn will stay if they receive discount price, then a prevention action can be performed by offering discount price. In this case, the discount will be offered to predicted-churn customer (case number 1 and 3). \n",
    "\n",
    "Case number 1, if the discounted price succeed to retain customer, then money loss is avoided.\n",
    "\n",
    "Case number 3, if the loyal customer use the discount, it seems that the company spend unnecessary cost (discounted price), but it may strengthen the customer loyalty.\n",
    "\n",
    "In case number 4, we loose the opportunity to prevent money loss.\n",
    "\n",
    "According to those cases, offcourse it would be important to improve the model performance. Since the purpose of this project is for gaining preliminary insight about problem-solving in telco churn prediction, I simply did undersampling for the imbalanced dataset. It would be better if oversampling is chosen or other approaches for imbalanced dataset. In addition, it is very important to cooperate with other departments (for example, Marketing dept.) to optimise the effectiveness of the discount price.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
